线性回归
=================

有监督学习
-----------
输入样本有标签

无监督学习
-----------
输入样本没有标签

泛化能力
---------
是指模型对于新样本的识别能力

欠拟合
-------
模型在训练数据集表现良好，测试数据集表现差

过拟合
-------
模型过于简单，没法很好的学习到数据背后的规律

偏差
---
是指预测值与真实值的差异，即模型精度

方差
---
是指模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性

交叉验证
-------
第一种是简单交叉验证，所谓的简单，是和其他交叉验证方法相对而言的。首先，我们随机的将样本数据分为两部分（比如： 70%的训练集，30%的测试集），然后用训练集来训练模型，在测试集上验证模型及参数。接着，我们再把样本打乱，重新选择训练集和测试集，继续训练数据和检验模型。最后我们选择损失函数评估最优的模型和参数。　

第二种是S折交叉验证（S-Folder Cross Validation）。和第一种方法不同，S折交叉验证会把样本数据随机的分成S份，每次随机的选择S-1份作为训练集，剩下的1份做测试集。当这一轮完成后，重新随机选择S-1份来训练数据。若干轮（小于S）之后，选择损失函数评估最优的模型和参数。

第三种是留一交叉验证（Leave-one-out Cross Validation），它是第二种情况的特例，此时S等于样本数N，这样对于N个样本，每次选择N-1个样本来训练数据，留一个样本来验证模型预测的好坏。此方法主要用于样本量非常少的情况，比如对于普通适中问题，N小于50时，我一般采用留一交叉验证。

sklearn.model_selection  train_test_spilt


